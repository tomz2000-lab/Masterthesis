=== Resource Allocation Game - Targeted Node Run ===
Job ID: 1754898, Node: jn118
=== Environment Check ===
CUDA: True, GPU: NVIDIA L40
NVIDIA L40, 49140 MiB, 1 MiB
=== Verifying Torch Scope Fix ===
âœ… Torch scope fix is present
=== Verifying Resource Allocation Game Updates ===
âœ… Role-based prompts are implemented
=== Running Resource Allocation Game - 10 Iterations ===
Game: Development Team vs Marketing Team resource negotiation
Utility Functions: Development=12x+3y+Îµ, Marketing=3x+12y+i

=== Iteration 1/10 ===
Mon Sep 29 05:06:11 PM CEST 2025: Starting resource allocation negotiation iteration 1
ğŸ”§ About to run Python command...
2025-09-29 17:06:14,907 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:06:14,908 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:06:14,908 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:06:14,924 - SessionManager - INFO - [6689c9d6-ac33-4b8b-a136-fd484374cfc3]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.71s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:06:16,130 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.86s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.86s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
âœ… Model loaded successfully in 13.15s (total since entry 13.87s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.50s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:06:29,453 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.87s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.26s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.50s/it]
2025-09-29 17:06:34,728 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:06:34,729 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:06:38,646 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:06:38,646 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:06:38,646 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:06:38,646 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:06:38,647 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:38,647 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:38,647 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:06:38,647 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:06:38,647 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:06:38,647 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:06:38,647 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:06:41,702 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:06:41,703 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:41,703 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:06:41,703 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:06:41,703 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:06:41,703 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:06:41,703 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:06:41,703 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 422.0
- ğŸ¯ RECOMMENDATION: ACCEPT! (422.0 > 280.0)

**ANALYSIS: This offer gives you 422.0 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +142.0 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:06:45,207 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:06:45,207 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:06:45,207 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:06:45,207 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 785.1
- ğŸ¯ RECOMMENDATION: ACCEPT! (785.1 > 420.0)

**ANALYSIS: This offer gives you 785.1 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +365.1 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:06:47,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:06:47,555 - SessionManager - INFO - [6689c9d6-ac33-4b8b-a136-fd484374cfc3]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.39s (total since entry 5.88s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
12, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=389.2 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=765.8 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=389.5 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=781.8 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 139.949021724043, 'model_b': 363.37631620496006}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 419.949021724043, 'model_b': 783.3763162049601}
Metrics: {'utility_surplus': {'model_a': 139.949021724043, 'model_b': 363.37631620496006}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 1 completed successfully
Mon Sep 29 05:06:48 PM CEST 2025: Completed iteration 1

=== Iteration 2/10 ===
Mon Sep 29 05:06:48 PM CEST 2025: Starting resource allocation negotiation iteration 2
ğŸ”§ About to run Python command...
2025-09-29 17:06:51,889 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:06:51,890 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:06:51,890 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:06:51,894 - SessionManager - INFO - [68f44971-e6fd-4530-ae1f-840f3fc84c1c]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.51s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:06:52,908 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.83s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.84s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
âœ… Model loaded successfully in 13.12s (total since entry 13.65s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
26, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.50s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:07:06,207 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.86s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:07:11,461 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:07:11,462 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:15,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:07:15,361 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:07:15,361 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:18,410 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:18,411 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:18,412 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:07:18,412 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:07:18,412 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 418.7
- ğŸ¯ RECOMMENDATION: ACCEPT! (418.7 > 280.0)

**ANALYSIS: This offer gives you 418.7 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +138.7 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:21,962 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:07:21,962 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:07:21,962 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:07:21,962 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 793.5
- ğŸ¯ RECOMMENDATION: ACCEPT! (793.5 > 420.0)

**ANALYSIS: This offer gives you 793.5 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +373.5 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:25,100 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:07:25,100 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:07:25,100 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:07:25,100 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:07:25,100 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:07:25,101 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:07:25,101 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:07:25,101 - SessionManager - INFO - [68f44971-e6fd-4530-ae1f-840f3fc84c1c]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.38s (total since entry 5.88s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
1, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=390.1 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=776.5 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=393.7 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=773.0 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 138.51957047927016, 'model_b': 348.4948320296297}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 418.51957047927016, 'model_b': 768.4948320296297}
Metrics: {'utility_surplus': {'model_a': 138.51957047927016, 'model_b': 348.4948320296297}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 2 completed successfully
Mon Sep 29 05:07:25 PM CEST 2025: Completed iteration 2

=== Iteration 3/10 ===
Mon Sep 29 05:07:25 PM CEST 2025: Starting resource allocation negotiation iteration 3
ğŸ”§ About to run Python command...
2025-09-29 17:07:29,465 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:07:29,465 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:07:29,465 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:07:29,469 - SessionManager - INFO - [5543ee5a-36ec-4b18-bc2c-0a95db8e9f2c]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.54s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:07:30,502 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.87s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.86s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
âœ… Model loaded successfully in 13.15s (total since entry 13.70s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:07:43,812 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.50s/it]
2025-09-29 17:07:49,085 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:07:49,085 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:52,997 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:07:52,997 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:07:52,997 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:56,075 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:07:56,075 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:07:56,075 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:07:56,076 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:07:56,076 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:07:56,076 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 422.5
- ğŸ¯ RECOMMENDATION: ACCEPT! (422.5 > 280.0)

**ANALYSIS: This offer gives you 422.5 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +142.5 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:07:59,650 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:07:59,651 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:07:59,651 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:07:59,651 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 787.2
- ğŸ¯ RECOMMENDATION: ACCEPT! (787.2 > 420.0)

**ANALYSIS: This offer gives you 787.2 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +367.2 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:08:02,740 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:08:02,741 - SessionManager - INFO - [5543ee5a-36ec-4b18-bc2c-0a95db8e9f2c]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.39s (total since entry 5.87s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
5, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=391.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=779.4 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=384.7 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=767.8 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 139.27495703231915, 'model_b': 358.1692184941853}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 419.27495703231915, 'model_b': 778.1692184941853}
Metrics: {'utility_surplus': {'model_a': 139.27495703231915, 'model_b': 358.1692184941853}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 3 completed successfully
Mon Sep 29 05:08:03 PM CEST 2025: Completed iteration 3

=== Iteration 4/10 ===
Mon Sep 29 05:08:03 PM CEST 2025: Starting resource allocation negotiation iteration 4
ğŸ”§ About to run Python command...
2025-09-29 17:08:07,073 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:08:07,073 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:08:07,073 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:08:07,075 - SessionManager - INFO - [acb83021-5259-4b8f-992a-1cfa09e18c99]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.51s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:08:08,084 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.87s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.83s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
âœ… Model loaded successfully in 13.15s (total since entry 13.67s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.49s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:08:21,410 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:08:26,681 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:08:26,681 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:08:30,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:08:30,575 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:08:30,575 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:08:33,588 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:08:33,588 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:08:33,588 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:08:33,588 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:08:33,588 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:33,588 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:08:33,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:08:33,589 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:08:33,589 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 421.3
- ğŸ¯ RECOMMENDATION: ACCEPT! (421.3 > 280.0)

**ANALYSIS: This offer gives you 421.3 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +141.3 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:08:37,045 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:08:37,045 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:08:37,045 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:08:37,045 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 779.1
- ğŸ¯ RECOMMENDATION: ACCEPT! (779.1 > 420.0)

**ANALYSIS: This offer gives you 779.1 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +359.1 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:08:40,023 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:08:40,023 - SessionManager - INFO - [acb83021-5259-4b8f-992a-1cfa09e18c99]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.40s (total since entry 5.89s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
4, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=389.3 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=791.1 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=389.3 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=771.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 142.57843610703048, 'model_b': 344.8857500976925}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 422.5784361070305, 'model_b': 764.8857500976925}
Metrics: {'utility_surplus': {'model_a': 142.57843610703048, 'model_b': 344.8857500976925}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 4 completed successfully
Mon Sep 29 05:08:40 PM CEST 2025: Completed iteration 4

=== Iteration 5/10 ===
Mon Sep 29 05:08:40 PM CEST 2025: Starting resource allocation negotiation iteration 5
ğŸ”§ About to run Python command...
2025-09-29 17:08:44,369 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:08:44,370 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:08:44,370 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:08:44,372 - SessionManager - INFO - [bf920bf6-80e7-4f8d-a5b5-593246510bcc]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:08:45,391 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.87s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.87s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.68s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.11s/it]
âœ… Model loaded successfully in 13.20s (total since entry 13.73s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
22, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.50s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:08:58,759 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.86s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:09:04,021 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:09:04,021 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:07,847 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:09:07,847 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:09:07,847 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:10,806 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:10,807 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:09:10,807 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:09:10,807 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 415.9
- ğŸ¯ RECOMMENDATION: ACCEPT! (415.9 > 280.0)

**ANALYSIS: This offer gives you 415.9 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +135.9 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:14,247 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:09:14,247 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:09:14,248 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:09:14,248 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 771.9
- ğŸ¯ RECOMMENDATION: ACCEPT! (771.9 > 420.0)

**ANALYSIS: This offer gives you 771.9 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +351.9 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:09:16,531 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:09:16,532 - SessionManager - INFO - [bf920bf6-80e7-4f8d-a5b5-593246510bcc]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.37s (total since entry 5.87s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=392.7 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=777.3 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=385.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=783.9 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 143.24345403620157, 'model_b': 358.27999263838865}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 423.24345403620157, 'model_b': 778.2799926383886}
Metrics: {'utility_surplus': {'model_a': 143.24345403620157, 'model_b': 358.27999263838865}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 5 completed successfully
Mon Sep 29 05:09:17 PM CEST 2025: Completed iteration 5

=== Iteration 6/10 ===
Mon Sep 29 05:09:17 PM CEST 2025: Starting resource allocation negotiation iteration 6
ğŸ”§ About to run Python command...
2025-09-29 17:09:20,867 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:09:20,867 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:09:20,867 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:09:20,868 - SessionManager - INFO - [4278b371-9b2c-4238-a09a-d73fb80434b1]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:09:21,888 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.85s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
âœ… Model loaded successfully in 13.10s (total since entry 13.63s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
29, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.49s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:09:35,152 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:09:40,390 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:09:40,390 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:44,370 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:09:44,370 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:09:44,370 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:44,370 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:44,371 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:44,371 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:44,371 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:44,371 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:44,371 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:09:44,371 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:09:44,371 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:09:47,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:09:47,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:09:47,471 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:09:47,471 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 419.6
- ğŸ¯ RECOMMENDATION: ACCEPT! (419.6 > 280.0)

**ANALYSIS: This offer gives you 419.6 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +139.6 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:51,057 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:09:51,057 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:09:51,057 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:09:51,057 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 792.1
- ğŸ¯ RECOMMENDATION: ACCEPT! (792.1 > 420.0)

**ANALYSIS: This offer gives you 792.1 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +372.1 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:09:54,158 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:09:54,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:09:54,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:09:54,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:09:54,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:09:54,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:09:54,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:09:54,159 - SessionManager - INFO - [4278b371-9b2c-4238-a09a-d73fb80434b1]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.35s (total since entry 5.84s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=388.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=784.8 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=391.2 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=773.4 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 140.68311820641878, 'model_b': 353.10742639263697}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 420.6831182064188, 'model_b': 773.107426392637}
Metrics: {'utility_surplus': {'model_a': 140.68311820641878, 'model_b': 353.10742639263697}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 6 completed successfully
Mon Sep 29 05:09:54 PM CEST 2025: Completed iteration 6

=== Iteration 7/10 ===
Mon Sep 29 05:09:54 PM CEST 2025: Starting resource allocation negotiation iteration 7
ğŸ”§ About to run Python command...
2025-09-29 17:09:58,490 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:09:58,490 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:09:58,490 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:09:58,493 - SessionManager - INFO - [7c7147d8-0b0f-429a-bc5e-44cbcc730561]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:09:59,512 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.86s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.83s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
âœ… Model loaded successfully in 13.16s (total since entry 13.69s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
2, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.55s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:10:12,898 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:10:18,151 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:10:18,151 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:10:21,945 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:10:21,945 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:10:21,945 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:10:24,937 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:24,938 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:24,938 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:10:24,938 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:10:24,938 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:10:24,938 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:10:24,938 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 419.4
- ğŸ¯ RECOMMENDATION: ACCEPT! (419.4 > 280.0)

**ANALYSIS: This offer gives you 419.4 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +139.4 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:10:28,455 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:10:28,455 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:10:28,455 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:10:28,455 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 787.0
- ğŸ¯ RECOMMENDATION: ACCEPT! (787.0 > 420.0)

**ANALYSIS: This offer gives you 787.0 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +367.0 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:10:31,512 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:10:31,512 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:10:31,512 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:10:31,512 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:10:31,512 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:10:31,512 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:10:31,513 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:10:31,513 - SessionManager - INFO - [7c7147d8-0b0f-429a-bc5e-44cbcc730561]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.37s (total since entry 5.92s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=389.5 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=784.3 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=391.4 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=787.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 138.61438442988788, 'model_b': 355.71485783289836}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 418.6143844298879, 'model_b': 775.7148578328984}
Metrics: {'utility_surplus': {'model_a': 138.61438442988788, 'model_b': 355.71485783289836}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 7 completed successfully
Mon Sep 29 05:10:32 PM CEST 2025: Completed iteration 7

=== Iteration 8/10 ===
Mon Sep 29 05:10:32 PM CEST 2025: Starting resource allocation negotiation iteration 8
ğŸ”§ About to run Python command...
2025-09-29 17:10:35,861 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:10:35,861 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:10:35,861 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:10:35,862 - SessionManager - INFO - [03b31265-ada2-44db-93ff-c686b6c8e1ee]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:10:36,882 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.86s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.86s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.83s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.68s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.11s/it]
âœ… Model loaded successfully in 13.17s (total since entry 13.71s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.49s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:10:50,220 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:10:55,468 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:10:55,468 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:10:59,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:10:59,298 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:10:59,298 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:02,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:11:02,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:11:02,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:02,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:02,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:02,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:02,293 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:11:02,293 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:11:02,293 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 426.1
- ğŸ¯ RECOMMENDATION: ACCEPT! (426.1 > 280.0)

**ANALYSIS: This offer gives you 426.1 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +146.1 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:05,752 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:11:05,752 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:11:05,752 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:11:05,752 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 781.0
- ğŸ¯ RECOMMENDATION: ACCEPT! (781.0 > 420.0)

**ANALYSIS: This offer gives you 781.0 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +361.0 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:08,742 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:11:08,742 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:11:08,743 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:11:08,743 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:11:08,743 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:11:08,743 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:11:08,743 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:11:08,743 - SessionManager - INFO - [03b31265-ada2-44db-93ff-c686b6c8e1ee]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.37s (total since entry 5.86s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
19, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=393.5 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=771.4 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=389.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=770.3 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 137.7592656166313, 'model_b': 356.37360670251167}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 417.7592656166313, 'model_b': 776.3736067025117}
Metrics: {'utility_surplus': {'model_a': 137.7592656166313, 'model_b': 356.37360670251167}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 8 completed successfully
Mon Sep 29 05:11:09 PM CEST 2025: Completed iteration 8

=== Iteration 9/10 ===
Mon Sep 29 05:11:09 PM CEST 2025: Starting resource allocation negotiation iteration 9
ğŸ”§ About to run Python command...
2025-09-29 17:11:13,097 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:11:13,097 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:11:13,097 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:11:13,099 - SessionManager - INFO - [ec5a7ad0-d8d7-4ba8-b7ae-4c2dc176758a]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.70s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:11:14,298 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.85s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.83s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
âœ… Model loaded successfully in 13.16s (total since entry 13.87s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
1, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.49s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:11:27,627 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:11:32,880 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:11:32,880 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:36,823 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:11:36,823 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:11:36,823 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:11:39,929 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:11:39,930 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:11:39,930 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:11:39,930 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 423.9
- ğŸ¯ RECOMMENDATION: ACCEPT! (423.9 > 280.0)

**ANALYSIS: This offer gives you 423.9 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +143.9 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:43,518 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:11:43,519 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:11:43,519 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:11:43,519 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 789.0
- ğŸ¯ RECOMMENDATION: ACCEPT! (789.0 > 420.0)

**ANALYSIS: This offer gives you 789.0 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +369.0 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:11:46,618 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:11:46,618 - SessionManager - INFO - [ec5a7ad0-d8d7-4ba8-b7ae-4c2dc176758a]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.37s (total since entry 5.87s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
24, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=390.7 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=771.3 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=387.5 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=783.0 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 141.25024340305123, 'model_b': 355.63469755813117}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 421.25024340305123, 'model_b': 775.6346975581312}
Metrics: {'utility_surplus': {'model_a': 141.25024340305123, 'model_b': 355.63469755813117}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 9 completed successfully
Mon Sep 29 05:11:47 PM CEST 2025: Completed iteration 9

=== Iteration 10/10 ===
Mon Sep 29 05:11:47 PM CEST 2025: Starting resource allocation negotiation iteration 10
ğŸ”§ About to run Python command...
2025-09-29 17:11:50,948 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 17:11:50,949 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 17:11:50,949 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 17:11:50,950 - SessionManager - INFO - [aa1ebf70-003f-401d-aba6-31b02af7c13c]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:11:51,972 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.85s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
âœ… Model loaded successfully in 13.13s (total since entry 13.67s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
18, 17823
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.49s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 17:12:05,276 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
2025-09-29 17:12:10,528 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:12:10,528 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:12:14,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:12:14,435 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:12:14,435 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:12:17,415 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:12:17,415 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:12:17,415 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:12:17,415 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:12:17,415 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,50):
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+50=70 â‰¤ 100 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 50 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,50): True
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 17:12:17,416 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 17:12:17,416 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 17:12:17,417 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 416.5
- ğŸ¯ RECOMMENDATION: ACCEPT! (416.5 > 280.0)

**ANALYSIS: This offer gives you 416.5 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +136.5 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:12:20,877 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:12:20,877 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:12:20,878 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 17:12:20,878 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 772.7
- ğŸ¯ RECOMMENDATION: ACCEPT! (772.7 > 420.0)

**ANALYSIS: This offer gives you 772.7 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +352.7 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 17:12:23,197 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 17:12:23,197 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 17:12:23,197 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 17:12:23,197 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 17:12:23,198 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 17:12:23,198 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 17:12:23,198 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 17:12:23,198 - SessionManager - INFO - [aa1ebf70-003f-401d-aba6-31b02af7c13c]  Finished â€“ agreement=True
âœ… Model loaded successfully in 5.36s (total since entry 5.86s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 22697
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 50}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 50}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 50.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=387.3 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=777.9 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=50):
  - Total: 20+50=70 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—50=260 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 50 â‰¥ 5?
  Positive: 20â‰¥0 and 50â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=390.4 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (20,50) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=774.4 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 139.84155443793782, 'model_b': 349.62334368221684}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
âš ï¸  Model model_a shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_b (shared name: meta-llama/Llama-3.2-3B-Instruct)
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 419.8415544379378, 'model_b': 769.6233436822168}
Metrics: {'utility_surplus': {'model_a': 139.84155443793782, 'model_b': 349.62334368221684}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 10 completed successfully
Mon Sep 29 05:12:23 PM CEST 2025: Completed iteration 10

=== Resource Allocation Game Batch Complete ===
Successful iterations: 10/10
Check output logs for negotiation results and final utilities
