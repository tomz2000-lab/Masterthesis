=== Resource Allocation Game - Targeted Node Run ===
Job ID: 1754225, Node: jn117
=== Environment Check ===
CUDA: True, GPU: NVIDIA L40
NVIDIA L40, 49140 MiB, 1 MiB
=== Verifying Torch Scope Fix ===
âœ… Torch scope fix is present
=== Verifying Resource Allocation Game Updates ===
âœ… Role-based prompts are implemented
=== Running Resource Allocation Game - 10 Iterations ===
Game: Development Team vs Marketing Team resource negotiation
Utility Functions: Development=12x+3y+Îµ, Marketing=3x+12y+i

=== Iteration 1/10 ===
Mon Sep 29 04:00:29 PM CEST 2025: Starting resource allocation negotiation iteration 1
ğŸ”§ About to run Python command...
2025-09-29 16:00:36,569 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:00:36,572 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:00:36,574 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:00:36,591 - SessionManager - INFO - [095b28da-d13d-429b-8d37-56986e35f65e]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.55s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:00:37,861 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.38s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  4.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.23s/it]
âœ… Model loaded successfully in 11.41s (total since entry 11.98s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
5, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:00:49,267 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:06<00:19,  6.53s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:13<00:13,  6.59s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:19<00:06,  6.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:21<00:00,  4.56s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:21<00:00,  5.31s/it]
2025-09-29 16:01:10,810 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:01:10,816 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:14,449 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:01:14,453 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:01:14,455 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:14,457 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:14,460 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:14,462 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:14,464 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:14,467 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:14,469 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:01:14,471 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:01:14,473 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:18,022 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:01:18,025 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:01:18,028 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:18,031 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:18,033 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:18,037 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:18,040 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:18,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:18,045 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:01:18,048 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:01:18,050 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:01:18,053 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:18,056 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:18,058 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:18,061 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:18,063 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:18,065 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:18,067 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:01:18,069 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:01:18,072 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:01:18,074 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:18,077 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:18,086 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:18,088 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:18,090 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:18,093 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:18,096 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:01:18,098 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:01:18,101 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 420.1
- ğŸ¯ RECOMMENDATION: ACCEPT! (420.1 > 280.0)

**ANALYSIS: This offer gives you 420.1 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +140.1 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:21,144 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:01:21,147 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:01:21,149 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:01:21,151 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 793.4
- ğŸ¯ RECOMMENDATION: ACCEPT! (793.4 > 420.0)

**ANALYSIS: This offer gives you 793.4 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +373.4 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:24,666 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:01:24,673 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:01:24,675 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:01:24,678 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:01:24,680 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:01:24,682 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:01:24,684 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:01:24,687 - SessionManager - INFO - [095b28da-d13d-429b-8d37-56986e35f65e]  Finished â€“ agreement=True
âœ… Model loaded successfully in 21.67s (total since entry 22.19s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
4, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=480.2 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=764.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=481.4 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=788.1 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 139.85906913617163, 'model_b': 368.43456878989446}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 419.8590691361716, 'model_b': 788.4345687898945}
Metrics: {'utility_surplus': {'model_a': 139.85906913617163, 'model_b': 368.43456878989446}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 1 completed successfully
Mon Sep 29 04:01:25 PM CEST 2025: Completed iteration 1

=== Iteration 2/10 ===
Mon Sep 29 04:01:25 PM CEST 2025: Starting resource allocation negotiation iteration 2
ğŸ”§ About to run Python command...
2025-09-29 16:01:29,059 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:01:29,062 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:01:29,064 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:01:29,070 - SessionManager - INFO - [39942406-f88e-402c-abbe-f43188777596]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:01:30,079 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:04<00:04,  4.06s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.38s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.63s/it]
âœ… Model loaded successfully in 5.99s (total since entry 6.52s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:01:36,238 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.05s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:08<00:08,  4.06s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:12<00:04,  4.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  2.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  3.27s/it]
2025-09-29 16:01:49,576 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:01:49,581 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:52,564 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:01:52,569 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:01:52,575 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:52,580 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:52,585 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:52,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:52,594 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:52,599 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:52,605 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:01:52,609 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:01:52,618 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:56,075 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:01:56,081 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:01:56,087 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:56,094 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:56,098 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:56,103 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:56,109 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:56,113 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:56,118 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:01:56,122 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:01:56,127 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:01:56,131 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:56,136 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:56,140 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:56,146 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:56,151 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:56,156 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:56,160 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:01:56,165 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:01:56,169 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:01:56,175 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:01:56,179 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:01:56,184 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:56,189 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:01:56,194 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:01:56,199 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:01:56,204 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:01:56,211 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:01:56,215 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 421.3
- ğŸ¯ RECOMMENDATION: ACCEPT! (421.3 > 280.0)

**ANALYSIS: This offer gives you 421.3 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +141.3 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:01:59,188 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:01:59,193 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:01:59,199 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:01:59,204 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 781.9
- ğŸ¯ RECOMMENDATION: ACCEPT! (781.9 > 420.0)

**ANALYSIS: This offer gives you 781.9 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +361.9 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:02:02,637 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:02:02,642 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:02:02,648 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:02:02,652 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:02:02,658 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:02:02,662 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:02:02,667 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:02:02,671 - SessionManager - INFO - [39942406-f88e-402c-abbe-f43188777596]  Finished â€“ agreement=True
âœ… Model loaded successfully in 13.46s (total since entry 13.94s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=476.6 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=778.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=477.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=790.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 140.2728733528644, 'model_b': 357.8303603933273}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 420.2728733528644, 'model_b': 777.8303603933273}
Metrics: {'utility_surplus': {'model_a': 140.2728733528644, 'model_b': 357.8303603933273}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 2 completed successfully
Mon Sep 29 04:02:03 PM CEST 2025: Completed iteration 2

=== Iteration 3/10 ===
Mon Sep 29 04:02:03 PM CEST 2025: Starting resource allocation negotiation iteration 3
ğŸ”§ About to run Python command...
2025-09-29 16:02:07,065 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:02:07,067 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:02:07,070 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:02:07,077 - SessionManager - INFO - [0a099955-a59e-44f3-a75f-c81d6428e2aa]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.51s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:02:08,098 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.48s/it]
âœ… Model loaded successfully in 5.71s (total since entry 6.23s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
1, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:02:13,953 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.82s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.83s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.80s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.65s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.08s/it]
2025-09-29 16:02:26,546 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:02:26,550 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:02:29,550 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:02:29,553 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:02:29,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:02:29,557 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:02:29,560 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:29,563 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:29,566 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:02:29,568 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:02:29,571 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:02:29,574 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:02:29,577 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:02:33,032 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:02:33,034 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:02:33,037 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:02:33,039 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:02:33,044 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:33,047 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:33,049 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:02:33,052 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:02:33,054 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:02:33,056 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:02:33,058 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:02:33,060 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:02:33,062 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:02:33,065 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:33,067 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:33,069 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:02:33,072 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:02:33,074 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:02:33,077 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:02:33,079 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:02:33,081 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:02:33,085 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:02:33,087 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:33,090 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:02:33,092 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:02:33,094 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:02:33,096 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:02:33,098 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:02:33,101 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 420.2
- ğŸ¯ RECOMMENDATION: ACCEPT! (420.2 > 280.0)

**ANALYSIS: This offer gives you 420.2 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +140.2 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:02:35,404 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:02:35,407 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:02:35,410 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:02:35,412 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 780.6
- ğŸ¯ RECOMMENDATION: ACCEPT! (780.6 > 420.0)

**ANALYSIS: This offer gives you 780.6 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +360.6 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:02:38,836 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:02:38,839 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:02:38,842 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:02:38,844 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:02:38,846 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:02:38,848 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:02:38,851 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:02:38,853 - SessionManager - INFO - [0a099955-a59e-44f3-a75f-c81d6428e2aa]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.71s (total since entry 13.19s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
7, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=480.0 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=774.4 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=478.1 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=793.5 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 135.90642503826723, 'model_b': 345.90824875297653}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 415.90642503826723, 'model_b': 765.9082487529765}
Metrics: {'utility_surplus': {'model_a': 135.90642503826723, 'model_b': 345.90824875297653}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 3 completed successfully
Mon Sep 29 04:02:39 PM CEST 2025: Completed iteration 3

=== Iteration 4/10 ===
Mon Sep 29 04:02:39 PM CEST 2025: Starting resource allocation negotiation iteration 4
ğŸ”§ About to run Python command...
2025-09-29 16:02:43,222 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:02:43,224 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:02:43,227 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:02:43,234 - SessionManager - INFO - [e1907f56-a894-4021-9c25-39b2ab42273b]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.51s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:02:44,231 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.48s/it]
âœ… Model loaded successfully in 5.69s (total since entry 6.21s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:02:50,083 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.85s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.10s/it]
2025-09-29 16:03:02,754 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:03:02,757 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:05,660 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:03:05,663 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:03:05,666 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:05,668 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:05,670 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:05,672 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:05,675 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:05,678 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:05,681 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:03:05,684 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:03:05,687 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:09,084 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:03:09,087 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:03:09,089 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:09,091 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:09,093 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:09,097 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:09,099 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:09,101 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:09,105 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:03:09,108 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:03:09,112 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:03:09,115 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:09,117 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:09,120 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:09,122 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:09,124 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:09,126 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:09,128 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:03:09,130 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:03:09,132 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:03:09,135 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:09,138 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:09,141 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:09,143 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:09,145 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:09,148 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:09,150 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:03:09,152 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:03:09,155 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 417.8
- ğŸ¯ RECOMMENDATION: ACCEPT! (417.8 > 280.0)

**ANALYSIS: This offer gives you 417.8 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +137.8 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:11,374 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:03:11,376 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:03:11,379 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:03:11,381 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 782.6
- ğŸ¯ RECOMMENDATION: ACCEPT! (782.6 > 420.0)

**ANALYSIS: This offer gives you 782.6 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +362.6 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:14,742 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:03:14,745 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:03:14,747 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:03:14,750 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:03:14,753 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:03:14,755 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:03:14,758 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:03:14,760 - SessionManager - INFO - [e1907f56-a894-4021-9c25-39b2ab42273b]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.78s (total since entry 13.26s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
9, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=477.2 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=766.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=482.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=765.7 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 138.39086254303953, 'model_b': 363.32205157929957}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 418.39086254303953, 'model_b': 783.3220515792996}
Metrics: {'utility_surplus': {'model_a': 138.39086254303953, 'model_b': 363.32205157929957}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 4 completed successfully
Mon Sep 29 04:03:15 PM CEST 2025: Completed iteration 4

=== Iteration 5/10 ===
Mon Sep 29 04:03:15 PM CEST 2025: Starting resource allocation negotiation iteration 5
ğŸ”§ About to run Python command...
2025-09-29 16:03:19,138 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:03:19,140 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:03:19,143 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:03:19,150 - SessionManager - INFO - [6b76619c-3371-4084-89a1-7f15f9f260a9]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:03:20,176 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
âœ… Model loaded successfully in 5.73s (total since entry 6.25s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.47s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:03:26,042 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.83s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.85s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
2025-09-29 16:03:38,714 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:03:38,722 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:41,824 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:03:41,831 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:03:41,837 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:41,842 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:41,849 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:41,853 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:41,859 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:41,864 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:41,871 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:03:41,877 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:03:41,882 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:45,459 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:03:45,466 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:03:45,471 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:45,476 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:45,481 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:45,487 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:45,494 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:45,498 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:45,505 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:03:45,510 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:03:45,515 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:03:45,520 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:45,525 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:45,529 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:45,540 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:45,545 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:45,549 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:45,555 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:03:45,560 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:03:45,565 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:03:45,570 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:03:45,576 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:03:45,580 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:45,585 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:03:45,592 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:03:45,597 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:03:45,602 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:03:45,609 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:03:45,614 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 418.0
- ğŸ¯ RECOMMENDATION: ACCEPT! (418.0 > 280.0)

**ANALYSIS: This offer gives you 418.0 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +138.0 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:47,950 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:03:47,956 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:03:47,962 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:03:47,968 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 776.6
- ğŸ¯ RECOMMENDATION: ACCEPT! (776.6 > 420.0)

**ANALYSIS: This offer gives you 776.6 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +356.6 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:03:51,515 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:03:51,521 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:03:51,527 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:03:51,532 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:03:51,537 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:03:51,542 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:03:51,547 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:03:51,553 - SessionManager - INFO - [6b76619c-3371-4084-89a1-7f15f9f260a9]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.79s (total since entry 13.27s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=481.2 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=789.3 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=481.5 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=793.5 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 139.79153463850054, 'model_b': 345.70095026429976}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 419.79153463850054, 'model_b': 765.7009502642998}
Metrics: {'utility_surplus': {'model_a': 139.79153463850054, 'model_b': 345.70095026429976}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 5 completed successfully
Mon Sep 29 04:03:52 PM CEST 2025: Completed iteration 5

=== Iteration 6/10 ===
Mon Sep 29 04:03:52 PM CEST 2025: Starting resource allocation negotiation iteration 6
ğŸ”§ About to run Python command...
2025-09-29 16:03:55,955 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:03:55,958 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:03:55,961 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:03:55,968 - SessionManager - INFO - [2bfdfbfd-ae4b-4330-bf7f-95a9964a755f]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.51s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:03:56,986 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.86s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.50s/it]
âœ… Model loaded successfully in 5.76s (total since entry 6.28s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:04:02,897 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.83s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.84s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
2025-09-29 16:04:15,543 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:04:15,546 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:04:18,571 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:04:18,574 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:04:18,576 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:18,579 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:18,582 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:18,585 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:18,589 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:18,592 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:18,595 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:04:18,597 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:04:18,599 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:04:22,095 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:04:22,097 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:04:22,100 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:22,103 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:22,105 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:22,108 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:22,114 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:22,117 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:22,121 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:04:22,124 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:04:22,127 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:04:22,130 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:22,132 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:22,135 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:22,137 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:22,140 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:22,142 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:22,145 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:04:22,147 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:04:22,150 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:04:22,153 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:22,156 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:22,159 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:22,161 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:22,163 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:22,166 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:22,169 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:04:22,172 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:04:22,174 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 420.2
- ğŸ¯ RECOMMENDATION: ACCEPT! (420.2 > 280.0)

**ANALYSIS: This offer gives you 420.2 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +140.2 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:04:24,505 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:04:24,508 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:04:24,511 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:04:24,514 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 789.8
- ğŸ¯ RECOMMENDATION: ACCEPT! (789.8 > 420.0)

**ANALYSIS: This offer gives you 789.8 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +369.8 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:04:27,981 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:04:27,984 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:04:27,987 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:04:27,989 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:04:27,992 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:04:27,996 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:04:27,999 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:04:28,002 - SessionManager - INFO - [2bfdfbfd-ae4b-4330-bf7f-95a9964a755f]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.76s (total since entry 13.25s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
12, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=479.3 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=792.9 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=477.3 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=767.5 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 138.25183264616282, 'model_b': 358.8669287256348}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 418.2518326461628, 'model_b': 778.8669287256348}
Metrics: {'utility_surplus': {'model_a': 138.25183264616282, 'model_b': 358.8669287256348}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 6 completed successfully
Mon Sep 29 04:04:28 PM CEST 2025: Completed iteration 6

=== Iteration 7/10 ===
Mon Sep 29 04:04:28 PM CEST 2025: Starting resource allocation negotiation iteration 7
ğŸ”§ About to run Python command...
2025-09-29 16:04:32,371 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:04:32,374 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:04:32,376 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:04:32,383 - SessionManager - INFO - [7ddc03f5-9488-46a3-b31a-ed5c868bc1ba]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:04:33,397 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
âœ… Model loaded successfully in 5.72s (total since entry 6.25s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:04:39,278 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.82s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.85s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
2025-09-29 16:04:51,911 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:04:51,914 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:04:54,913 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:04:54,916 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:04:54,918 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:54,921 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:54,923 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:54,925 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:54,928 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:54,931 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:54,932 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:04:54,935 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:04:54,937 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:04:58,442 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:04:58,446 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:04:58,448 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:58,451 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:58,453 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:58,456 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:58,459 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:58,462 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:58,464 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:04:58,467 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:04:58,470 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:04:58,473 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:58,478 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:58,480 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:58,483 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:58,486 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:58,488 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:58,490 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:04:58,494 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:04:58,496 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:04:58,499 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:04:58,502 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:04:58,505 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:58,508 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:04:58,511 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:04:58,514 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:04:58,517 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:04:58,519 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:04:58,524 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 416.9
- ğŸ¯ RECOMMENDATION: ACCEPT! (416.9 > 280.0)

**ANALYSIS: This offer gives you 416.9 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +136.9 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:05:00,861 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:05:00,864 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:05:00,867 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:05:00,870 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 780.6
- ğŸ¯ RECOMMENDATION: ACCEPT! (780.6 > 420.0)

**ANALYSIS: This offer gives you 780.6 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +360.6 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:05:04,344 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:05:04,348 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:05:04,352 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:05:04,355 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:05:04,357 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:05:04,359 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:05:04,361 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:05:04,363 - SessionManager - INFO - [7ddc03f5-9488-46a3-b31a-ed5c868bc1ba]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.75s (total since entry 13.23s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
9, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=478.9 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=769.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=481.3 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=776.1 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 140.53188618465344, 'model_b': 346.0499531767589}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 420.53188618465344, 'model_b': 766.0499531767589}
Metrics: {'utility_surplus': {'model_a': 140.53188618465344, 'model_b': 346.0499531767589}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 7 completed successfully
Mon Sep 29 04:05:05 PM CEST 2025: Completed iteration 7

=== Iteration 8/10 ===
Mon Sep 29 04:05:05 PM CEST 2025: Starting resource allocation negotiation iteration 8
ğŸ”§ About to run Python command...
2025-09-29 16:05:08,718 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:05:08,720 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:05:08,723 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:05:08,729 - SessionManager - INFO - [4841404a-a1c5-4203-b511-8c8f83132ab7]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.52s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:05:09,763 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
âœ… Model loaded successfully in 5.84s (total since entry 6.38s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:05:15,759 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.82s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.84s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
2025-09-29 16:05:28,373 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:05:28,376 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:05:31,292 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:05:31,296 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:05:31,298 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:05:31,301 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:05:31,304 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:31,306 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:31,309 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:05:31,312 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:05:31,315 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:05:31,317 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:05:31,320 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:05:34,714 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:05:34,717 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:05:34,720 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:05:34,723 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:05:34,725 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:34,728 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:34,731 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:05:34,734 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:05:34,737 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:05:34,739 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:05:34,742 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:05:34,745 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:05:34,747 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:05:34,749 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:34,752 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:34,756 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:05:34,758 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:05:34,761 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:05:34,764 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:05:34,766 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:05:34,769 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:05:34,772 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:05:34,774 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:34,777 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:05:34,780 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:05:34,782 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:05:34,785 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:05:34,787 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:05:34,790 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 419.6
- ğŸ¯ RECOMMENDATION: ACCEPT! (419.6 > 280.0)

**ANALYSIS: This offer gives you 419.6 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +139.6 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:05:37,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:05:37,010 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:05:37,013 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:05:37,016 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 777.5
- ğŸ¯ RECOMMENDATION: ACCEPT! (777.5 > 420.0)

**ANALYSIS: This offer gives you 777.5 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +357.5 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:05:40,385 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:05:40,395 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:05:40,404 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:05:40,412 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:05:40,422 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:05:40,431 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:05:40,442 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:05:40,450 - SessionManager - INFO - [4841404a-a1c5-4203-b511-8c8f83132ab7]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.74s (total since entry 13.22s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
28, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=480.2 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=794.9 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=481.6 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=769.0 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 141.30094515037229, 'model_b': 355.24054572262173}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 421.3009451503723, 'model_b': 775.2405457226217}
Metrics: {'utility_surplus': {'model_a': 141.30094515037229, 'model_b': 355.24054572262173}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 8 completed successfully
Mon Sep 29 04:05:41 PM CEST 2025: Completed iteration 8

=== Iteration 9/10 ===
Mon Sep 29 04:05:41 PM CEST 2025: Starting resource allocation negotiation iteration 9
ğŸ”§ About to run Python command...
2025-09-29 16:05:44,838 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:05:44,841 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:05:44,842 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:05:44,849 - SessionManager - INFO - [89fc9f44-cbd9-4022-8eae-3cba590aec98]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.51s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:05:45,855 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
âœ… Model loaded successfully in 5.74s (total since entry 6.27s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
13, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:05:51,758 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.81s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.84s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
2025-09-29 16:06:04,387 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:06:04,391 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:07,435 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:06:07,438 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:06:07,441 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:07,444 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:07,446 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:07,448 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:07,450 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:07,453 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:07,455 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:06:07,458 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:06:07,460 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:10,991 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:11,005 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:11,006 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:06:11,006 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:06:11,006 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 418.4
- ğŸ¯ RECOMMENDATION: ACCEPT! (418.4 > 280.0)

**ANALYSIS: This offer gives you 418.4 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +138.4 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:13,362 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:06:13,362 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:06:13,362 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:06:13,362 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 776.3
- ğŸ¯ RECOMMENDATION: ACCEPT! (776.3 > 420.0)

**ANALYSIS: This offer gives you 776.3 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +356.3 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:06:16,867 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:06:16,867 - SessionManager - INFO - [89fc9f44-cbd9-4022-8eae-3cba590aec98]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.75s (total since entry 13.22s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=477.7 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=793.8 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=480.8 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=790.2 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 137.09806867910038, 'model_b': 362.3930908308405}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 417.0980686791004, 'model_b': 782.3930908308405}
Metrics: {'utility_surplus': {'model_a': 137.09806867910038, 'model_b': 362.3930908308405}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 9 completed successfully
Mon Sep 29 04:06:17 PM CEST 2025: Completed iteration 9

=== Iteration 10/10 ===
Mon Sep 29 04:06:17 PM CEST 2025: Starting resource allocation negotiation iteration 10
ğŸ”§ About to run Python command...
2025-09-29 16:06:21,249 - negotiation_platform.core.game_engine - INFO - Registered game type: company_car
2025-09-29 16:06:21,249 - negotiation_platform.core.game_engine - INFO - Registered game type: resource_allocation
2025-09-29 16:06:21,249 - negotiation_platform.core.game_engine - INFO - Registered game type: integrative_negotiations
2025-09-29 16:06:21,254 - SessionManager - INFO - [2fe0876b-2867-4f73-b8bc-4fd45a4dd905]  âœ  Starting new session for game 'resource_allocation'
=== Negotiation Platform ===
Available models: ['model_a', 'model_b', 'model_c']
Using models: ['model_a', 'model_b', 'model_c']

=== Running Single Resource Allocation Negotiation ===
[DEBUG] LLMManager received model_configs: {'model_a': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_b': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}, 'model_c': {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}}
[DEBUG] Type of model_configs: <class 'dict'>
[DEBUG] Keys in model_configs: ['model_a', 'model_b', 'model_c']
[DEBUG] Attempting to register 3 models...
[DEBUG] Processing model: model_a
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.2-3B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_a (new instance for meta-llama/Llama-3.2-3B-Instruct)
[DEBUG] Processing model: model_b
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model: model_b (new instance for meta-llama/Llama-3.1-8B-Instruct)
[DEBUG] Processing model: model_c
[DEBUG] Model config: {'type': 'huggingface', 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'config': {'device': 'cuda', 'device_map': 'auto', 'temperature': 0.0, 'max_length': 1024, 'do_sample': False, 'pad_token_id': 50256, 'trust_remote_code': True, 'load_in_8bit': False}}
ğŸ“ Registered model alias: model_c -> meta-llama/Llama-3.1-8B-Instruct
ğŸ“Š Registered metric: utility_surplus - Utility Surplus
ğŸ“Š Registered metric: risk_minimization - Risk Minimization
ğŸ“Š Registered metric: deadline_sensitivity - Deadline Sensitivity
ğŸ“Š Registered metric: feasibility - Feasibility
ğŸ”„ Models will be loaded on-demand: ['model_a', 'model_b', 'model_c']
ğŸ”„ [DEBUG] Loading model: model_a
ğŸš€ Loading model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
Loading meta-llama/Llama-3.2-3B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.55s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.2-3B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:06:22,314 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.49s/it]
âœ… Model loaded successfully in 5.72s (total since entry 6.29s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 7381
âœ… meta-llama/Llama-3.2-3B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_a]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loading model: model_b
ğŸš€ Loading model: model_b (shared name: meta-llama/Llama-3.1-8B-Instruct)
Loading meta-llama/Llama-3.1-8B-Instruct...
ğŸ”§ TorchDynamo is DISABLED via environment variable
ğŸ”§ Environment: transformers=4.53.2, torch=2.7.1+cu126
ğŸ”§ CUDA available: True, device_count: 1
ğŸ” Starting tokenizer.from_pretrained()
âœ… Tokenizer loaded in 0.48s
ğŸ”§ Building model kwargs...
ğŸ”§ Using configured device_map: auto
âœ… Model kwargs built in 0.00s
ï¿½ Model kwargs keys: ['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map']
ğŸ”§ device_map: auto
ğŸ”§ torch_dtype: torch.float16
ğŸ”§ low_cpu_mem_usage: True
ğŸ”§ trust_remote_code: True
ï¿½ğŸ” Starting AutoModelForCausalLM.from_pretrained() with model_name='meta-llama/Llama-3.1-8B-Instruct'
ğŸ”§ About to call: AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.1-8B-Instruct', **['token', 'torch_dtype', 'trust_remote_code', 'low_cpu_mem_usage', 'device_map'])
2025-09-29 16:06:28,189 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸ”§ Starting model load (optimized settings)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.84s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:12<00:00,  3.09s/it]
2025-09-29 16:06:40,810 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:06:40,810 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Development Team. You value GPU hours more highly.
**SUGGESTED OPENING:** Consider offering around (30, 45) - high GPU hours for your needs.
**CONSTRAINT CHECK:** (30,45) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 270â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:43,857 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:43,858 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:06:43,858 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:06:43,858 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**No offers have been made yet. You should make the opening offer.**

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**ROLE:** You are the Marketing Team. You value bandwidth more highly.
**SUGGESTED OPENING:** Consider offering around (25, 50) - high bandwidth for your needs.
**CONSTRAINT CHECK:** (25,50) â†’ Total: 75â‰¤100 âœ…, GPU-BW: 275â‰¤300 âœ…, Valid!
**EXACT JSON:** {"type": "offer", "gpu_hours": 25, "bandwidth": 50}
**ACTION REQUIRED:** Make an opening offer with: {"type": "offer", "gpu_hours": X, "bandwidth": Y}
**CRITICAL:** Verify your offer satisfies ALL constraints above!

**CONSTRAINTS - ALL OFFERS MUST SATISFY:**
1. **Total Resources:** gpu_hours + bandwidth â‰¤ 100
2. **GPU-Bandwidth Limit:** 3Ã—gpu_hours + 4Ã—bandwidth â‰¤ 300
3. **Minimum GPU:** gpu_hours â‰¥ 5
4. **Minimum Bandwidth:** bandwidth â‰¥ 5

**Your Options:**
1. Make an offer: Specify allocation (gpu_hours=X, bandwidth=Y)
2. Accept: Accept the current proposal
3. Reject: Reject and continue negotiation

**RESPONSE FORMAT:** Respond with ONLY valid JSON. No explanations.
Valid responses:
{"type": "offer", "gpu_hours": 25, "bandwidth": 40}
{"type": "accept"}
{"type": "reject"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:47,429 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (35,20):
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 35+20=55 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 35 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (35,20): True
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” DETAILED CONSTRAINT CHECK for (20,60):
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Total: 20+60=80 â‰¤ 100 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min GPU: 20 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Min BW: 60 â‰¥ 5 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   Positive: xâ‰¥0 and yâ‰¥0 â†’ âœ…
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING -   FINAL RESULT: True
2025-09-29 16:06:47,430 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” CONSTRAINT CHECK for (20,60): True
2025-09-29 16:06:47,431 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_a:
2025-09-29 16:06:47,431 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 280.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 421.2
- ğŸ¯ RECOMMENDATION: ACCEPT! (421.2 > 280.0)

**ANALYSIS: This offer gives you 421.2 utility, which is BETTER than your BATNA of 280.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +141.2 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:50,507 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:06:50,507 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:06:50,508 - SessionManager - INFO - ğŸ¯ [PROMPT DEBUG] Prompt for model_b:
2025-09-29 16:06:50,508 - SessionManager - INFO - ğŸ“ FULL PROMPT: 
**Round 1/5 - Resource Allocation Negotiation**
Your current BATNA: 420.0

**Latest Proposal:**
- GPU Hours: 20, Bandwidth: 60
- Your utility from this: 769.2
- ğŸ¯ RECOMMENDATION: ACCEPT! (769.2 > 420.0)

**ANALYSIS: This offer gives you 769.2 utility, which is BETTER than your BATNA of 420.0. YOU SHOULD ACCEPT THIS OFFER.**

**ğŸš¨ CRITICAL: This is an EXCELLENT offer with +349.2 utility above your BATNA! ACCEPT immediately!**

**DECISION REQUIRED:** This offer is better than your BATNA.
**RECOMMENDED ACTION:** Accept with: {"type": "accept"}

**IMPORTANT: You should accept this proposal immediately.**

Required response:
{"type": "accept"}

**CRITICAL JSON REQUIREMENTS:**
- For offers: MUST include both 'gpu_hours' and 'bandwidth' with numeric values
- Example: {"type": "offer", "gpu_hours": 30, "bandwidth": 45}
- DO NOT send incomplete JSON like {"type": "offer"}
- Your offer MUST satisfy the constraints shown above!

Your response:
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
2025-09-29 16:06:54,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_b: {'type': 'accept'}
2025-09-29 16:06:54,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_b accepts current offer
2025-09-29 16:06:54,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ” [VALIDATION] Player model_a: {'type': 'accept'}
2025-09-29 16:06:54,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING - âœ… [ACCEPT] Player model_a accepts current offer
2025-09-29 16:06:54,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [ACCEPT PROCESSING] model_a accepting offer...
2025-09-29 16:06:54,043 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ¯ [AGREEMENT REACHED] Accepting offer (20,60)
2025-09-29 16:06:54,044 - negotiation_platform.games.resource_exchange_car_structure - WARNING - ğŸ‰ [GAME COMPLETE] Agreement: (20,60), Round: 1
2025-09-29 16:06:54,044 - SessionManager - INFO - [2fe0876b-2867-4f73-b8bc-4fd45a4dd905]  Finished â€“ agreement=True
âœ… Model loaded successfully in 12.74s (total since entry 13.22s)
ğŸ”§ [INFO] First model parameter device after load: cuda:0
ğŸ”§ [GPU] nvidia-smi output:
0, 23951
âœ… meta-llama/Llama-3.1-8B-Instruct loaded successfully
ğŸ”„ [DEBUG] Loaded model type: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Loaded model is None: False
ğŸ”„ [DEBUG] stored in loaded_agents[model_b]: <class 'negotiation_platform.models.hf_model_wrapper.HuggingFaceModelWrapper'>
ğŸ”„ [DEBUG] Final loaded_agents keys: ['model_a', 'model_b']
ğŸ”„ [DEBUG] Players list: ['model_a', 'model_b']
ğŸ”§ CONSTRAINT INIT: total_resources=100, constraints={'gpu_bandwidth': 300, 'min_gpu': 5, 'min_bandwidth': 5}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 35, "bandwidth": 20}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 35, 'bandwidth': 20}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 35.0, 'bandwidth': 20.0}
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=483.4 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "offer", "gpu_hours": 20, "bandwidth": 60}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'offer', 'gpu_hours': 20, 'bandwidth': 60}
âœ… [DEBUG] Pydantic validation successful: {'type': 'propose', 'gpu_hours': 20.0, 'bandwidth': 60.0}
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=789.6 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=35, bandwidth=20):
  - Total: 35+20=55 â‰¤ 100?
  - GPU-BW: 3Ã—35+4Ã—20=185 â‰¤ 300?
  - Min GPU: 35 â‰¥ 5?
  - Min BW: 20 â‰¥ 5?
  Positive: 35â‰¥0 and 20â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=479.7 â‰¥ BATNA=280.0?
ğŸ¯ [RESULT] Offer (35,20) â†’ VALID (all constraints satisfied)
ğŸ§® [CALC] Checking (gpu_hours=20, bandwidth=60):
  - Total: 20+60=80 â‰¤ 100?
  - GPU-BW: 3Ã—20+4Ã—60=300 â‰¤ 300?
  - Min GPU: 20 â‰¥ 5?
  - Min BW: 60 â‰¥ 5?
  Positive: 20â‰¥0 and 60â‰¥0 â†’ âœ…
  FINAL RESULT: VALID âœ…
  - BATNA Check: utility=768.2 â‰¥ BATNA=420.0?
ğŸ¯ [RESULT] Offer (20,60) â†’ VALID (all constraints satisfied)
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON after prefix removal: '{\n  "type": "accept"\n}'
ğŸ” [DEBUG] Raw LLM response: '{\n  "type": "accept"\n}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
ğŸ”§ [DEBUG] Model device: cuda:0
ğŸ”§ [DEBUG] Moved inputs to device: cuda:0
ğŸ§¹ [DEBUG] Extracted JSON from start: '{"type": "accept"}'
ğŸ” [DEBUG] Raw LLM response: '{"type": "accept"}'
âœ… [DEBUG] Successfully parsed JSON from start: {'type': 'accept'}
âœ… [DEBUG] Pydantic validation successful: {'type': 'accept'}
âœ… Calculated utility_surplus: {'model_a': 140.14656489048684, 'model_b': 364.26317319360464}
âœ… Calculated risk_minimization: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated deadline_sensitivity: {'model_a': 0.0, 'model_b': 0.0}
âœ… Calculated feasibility: {'model_a': 1.0, 'model_b': 1.0}
ğŸ—‘ï¸  meta-llama/Llama-3.2-3B-Instruct unloaded
ğŸ—‘ï¸  Unloaded model: model_a (shared name: meta-llama/Llama-3.2-3B-Instruct)
âš ï¸  Model model_b shares wrapper 'meta-llama/Llama-3.1-8B-Instruct' with aliases ['model_c']; skipping unload to avoid breaking aliases
Agreement reached: True
Agreement round: 1
Final utilities: {'model_a': 420.14656489048684, 'model_b': 784.2631731936046}
Metrics: {'utility_surplus': {'model_a': 140.14656489048684, 'model_b': 364.26317319360464}, 'risk_minimization': {'model_a': 0.0, 'model_b': 0.0}, 'deadline_sensitivity': {'model_a': 0.0, 'model_b': 0.0}, 'feasibility': {'model_a': 1.0, 'model_b': 1.0}}
ğŸ”„ Keeping models loaded for potential reuse

Platform completed successfully!
ğŸ”§ Python command exit code: 0
âœ… Iteration 10 completed successfully
Mon Sep 29 04:06:54 PM CEST 2025: Completed iteration 10

=== Resource Allocation Game Batch Complete ===
Successful iterations: 10/10
Check output logs for negotiation results and final utilities
