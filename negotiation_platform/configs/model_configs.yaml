# Model configuration file for negotiation platform
#mistralai/Ministral-8B-Instruct-2410
#mistralai/Mistral-7B-Instruct-v0.3
#meta-llama/Llama-3.1-8B-Instruct
#meta-llama/Llama-3.2-3B-Instruct
#Qwen/Qwen2.5-3B
#Qwen/Qwen2.5-7B

model_a:
  type: "huggingface"
  model_name: "meta-llama/Llama-3.1-8B-Instruct"
  config:
    device: "cuda"
    device_map: "auto"
    temperature: 0.7
    max_length: 16
    do_sample: true
    trust_remote_code: true
    load_in_8bit: false
    api_token: #put your HF token here if needed
    


model_b:
  type: "huggingface"
  model_name: "Qwen/Qwen2.5-7B"
  config:
    device: "cuda"
    device_map: "auto"
    temperature: 0.7
    max_length: 16
    do_sample: true
    trust_remote_code: true
    load_in_8bit: false
    api_token: #put your HF token here if needed

model_c:
  type: "huggingface"
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
  config:
    device: "cuda"
    device_map: "auto"
    temperature: 0.0
    max_length: 16
    do_sample: false
    pad_token_id: 50256
    trust_remote_code: true
    load_in_8bit: false
    api_token: #put your HF token here if needed